from flask import Flask, render_template, request, jsonify, send_from_directory, Response
from werkzeug.utils import secure_filename
import os
import json
import shutil
import tempfile
import zipfile
from pathlib import Path
from dotenv import load_dotenv, find_dotenv
from utils.annotator import GPTAnnotator
from utils.visualizer import visualize_annotations
try:
    from . import db as dbm
except Exception:
    try:
        from ShowUI.annotation_pipeline import db as dbm
    except Exception:
        import db as dbm
import threading
import queue
import time
import uuid
from concurrent.futures import ThreadPoolExecutor, as_completed

# Load environment variables robustly (works regardless of CWD)
dotenv_path = find_dotenv(usecwd=True)
if dotenv_path:
    load_dotenv(dotenv_path=dotenv_path, override=False)
else:
    # Fallback: load .env from the script directory if present
    script_env = (Path(__file__).resolve().parent / '.env')
    if script_env.exists():
        load_dotenv(dotenv_path=script_env, override=False)

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'data/images'
app.config['ANNOTATION_FOLDER'] = 'data/annotations'
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'dev-secret-key')

# Get max file size from env (in MB)
max_size_mb = int(os.getenv('MAX_FILE_SIZE_MB', '16'))
app.config['MAX_CONTENT_LENGTH'] = max_size_mb * 1024 * 1024

# Ensure folders exist
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(app.config['ANNOTATION_FOLDER'], exist_ok=True)
dbm.init_db()

# Initialize annotator
try:
    annotator = GPTAnnotator()
except ValueError as e:
    print(f"âŒ Error: {e}")
    print("The application requires a valid OpenAI API key to function.")
    print("Please set OPENAI_API_KEY in your .env file and restart the server.")
    exit(1)


########################
# Batch Job Infrastructure
########################

class BatchJobManager:
    def __init__(self, max_workers: int = None):
        try:
            max_workers_env = int(os.getenv('BATCH_MAX_WORKERS', '3'))
        except Exception:
            max_workers_env = 3
        self.max_workers = max_workers if max_workers is not None else max_workers_env
        self.executor = ThreadPoolExecutor(max_workers=self.max_workers)
        self.jobs = {}
        self.job_events = {}
        self.lock = threading.Lock()

    def create_job(self, images: list, force: bool) -> str:
        job_id = str(uuid.uuid4())
        with self.lock:
            self.jobs[job_id] = {
                'status': 'running',
                'total': len(images),
                'completed': 0,
                'success': 0,
                'skipped': 0,
                'errors': 0,
                'results': [],
                'force': force,
                'created_at': time.time(),
            }
            self.job_events[job_id] = queue.Queue()

        # submit tasks
        for img in images:
            self.executor.submit(self._process_image_task, job_id, img, force)

        # also start a monitor thread to finalize when complete
        threading.Thread(target=self._monitor_job_done, args=(job_id,), daemon=True).start()
        return job_id

    def _monitor_job_done(self, job_id: str):
        # Wait until completed == total then send complete event
        while True:
            with self.lock:
                job = self.jobs.get(job_id)
                if not job:
                    return
                if job['completed'] >= job['total']:
                    job['status'] = 'complete'
                    self._emit(job_id, {
                        'type': 'complete',
                        'summary': {
                            'total': job['total'],
                            'success': job['success'],
                            'skipped': job['skipped'],
                            'errors': job['errors'],
                        }
                    })
                    # small delay then close stream by placing a sentinel
                    self._emit(job_id, {'type': 'end'})
                    return
            time.sleep(0.2)

    def _emit(self, job_id: str, payload: dict):
        q = self.job_events.get(job_id)
        if q:
            try:
                q.put_nowait(payload)
            except Exception:
                pass

    def _process_image_task(self, job_id: str, img_entry: dict, force: bool):
        image_folder = Path(app.config['UPLOAD_FOLDER'])
        annotation_folder = Path(app.config['ANNOTATION_FOLDER'])
        img_path: Path = img_entry['path']
        relative_path = str(img_path.relative_to(image_folder)).replace('\\', '/')
        # Preserve folder structure for annotations
        rel_parts = Path(relative_path)
        annotation_path = annotation_folder / rel_parts.parent / f"{rel_parts.stem}.json"

        # Skip logic
        if annotation_path.exists() and not force:
            with self.lock:
                job = self.jobs.get(job_id)
                if job:
                    job['completed'] += 1
                    job['skipped'] += 1
                    job['results'].append({'filename': relative_path, 'status': 'skipped'})
            self._emit(job_id, {
                'type': 'image_done',
                'filename': relative_path,
                'status': 'skipped',
                'completed': self.jobs.get(job_id, {}).get('completed', 0),
                'total': self.jobs.get(job_id, {}).get('total', 0),
            })
            return

        # Preprocess
        try:
            self._emit(job_id, {'type': 'preprocess_start', 'filename': relative_path})
            hints = annotator._compute_preprocess_hints(str(img_path), max_elements=annotator.preprocess_max_elements)
            self._emit(job_id, {'type': 'preprocessed', 'filename': relative_path, 'hints': len(hints)})
        except Exception as e:
            with self.lock:
                job = self.jobs.get(job_id)
                if job:
                    job['completed'] += 1
                    job['errors'] += 1
                    job['results'].append({'filename': relative_path, 'status': 'error', 'error': f'Preprocess failed: {e}'})
            self._emit(job_id, {
                'type': 'image_done',
                'filename': relative_path,
                'status': 'error',
                'error': f'Preprocess failed: {e}',
                'completed': self.jobs.get(job_id, {}).get('completed', 0),
                'total': self.jobs.get(job_id, {}).get('total', 0),
            })
            return

        # Send OpenAI request with hints
        try:
            self._emit(job_id, {'type': 'request_sent', 'filename': relative_path})
            annotation = annotator.annotate_with_hints(str(img_path), hints)
            annotation_path.parent.mkdir(parents=True, exist_ok=True)
            with open(annotation_path, 'w') as f:
                json.dump(annotation, f, indent=2)
            try:
                # mark annotated in DB
                dbm.set_has_annotation(relative_path, True)
            except Exception:
                pass
            with self.lock:
                job = self.jobs.get(job_id)
                if job:
                    job['completed'] += 1
                    job['success'] += 1
                    job['results'].append({'filename': relative_path, 'status': 'success'})
            self._emit(job_id, {
                'type': 'image_done',
                'filename': relative_path,
                'status': 'success',
                'completed': self.jobs.get(job_id, {}).get('completed', 0),
                'total': self.jobs.get(job_id, {}).get('total', 0),
            })
        except Exception as e:
            with self.lock:
                job = self.jobs.get(job_id)
                if job:
                    job['completed'] += 1
                    job['errors'] += 1
                    job['results'].append({'filename': relative_path, 'status': 'error', 'error': str(e)})
            self._emit(job_id, {
                'type': 'image_done',
                'filename': relative_path,
                'status': 'error',
                'error': str(e),
                'completed': self.jobs.get(job_id, {}).get('completed', 0),
                'total': self.jobs.get(job_id, {}).get('total', 0),
            })

    def get_job(self, job_id: str):
        with self.lock:
            return dict(self.jobs.get(job_id, {}))

    def sse_stream(self, job_id: str):
        q = self.job_events.get(job_id)
        if not q:
            # empty stream end
            def _gen_empty():
                yield "event: end\n\n"
            return _gen_empty()

        def _gen():
            # initial snapshot
            with self.lock:
                job = self.jobs.get(job_id)
                if job:
                    init_payload = {
                        'type': 'init',
                        'total': job['total'],
                        'completed': job['completed'],
                        'success': job['success'],
                        'skipped': job['skipped'],
                        'errors': job['errors'],
                    }
                    yield f"data: {json.dumps(init_payload)}\n\n"
            # stream events
            while True:
                try:
                    payload = q.get(timeout=15)
                except Exception:
                    # heartbeat to keep connection alive
                    yield ": keep-alive\n\n"
                    continue
                if not isinstance(payload, dict):
                    continue
                if payload.get('type') == 'end':
                    yield f"event: end\n\n"
                    return
                yield f"data: {json.dumps(payload)}\n\n"

        return _gen()


job_manager = BatchJobManager()

@app.route('/')
def index():
    """Render main page"""
    return render_template('index.html')


@app.route('/api/images')
def get_images():
    """Get list of images with pagination, backed by SQLite. Falls back to FS if DB empty."""
    # pagination params
    try:
        page = int(request.args.get('page', '1'))
        page_size = int(request.args.get('page_size', '500'))
        if page < 1:
            page = 1
        if page_size < 1:
            page_size = 500
        if page_size > 5000:
            page_size = 5000
    except Exception:
        page, page_size = 1, 500

    total = dbm.count_images()
    if total == 0:
        # First time: index from filesystem quickly and return
        images = []
        folders_found = set()
        image_folder = Path(app.config['UPLOAD_FOLDER'])
        annotation_folder = Path(app.config['ANNOTATION_FOLDER'])
        for img_path in image_folder.rglob('*'):
            if img_path.is_file() and img_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']:
                rel = str(img_path.relative_to(image_folder)).replace('\\', '/')
                
                # Track folder if image is in a subfolder
                if '/' in rel:
                    folder = rel.split('/')[0]
                    folders_found.add(folder)
                
                # Check new folder-preserving path first, then legacy flat path
                rel_parts = Path(rel)
                ann_new = annotation_folder / rel_parts.parent / f"{rel_parts.stem}.json"
                ann_old = annotation_folder / f"{img_path.stem}.json"
                if ann_new.exists():
                    ann = ann_new
                    has_ann = True
                elif ann_old.exists():
                    ann = ann_old
                    has_ann = True
                else:
                    ann = ann_new
                    has_ann = False
                try:
                    size_b = img_path.stat().st_size
                except Exception:
                    size_b = None
                # upsert to DB
                try:
                    dbm.upsert_image(rel, has_annotation=has_ann, size_bytes=size_b)
                except Exception:
                    pass
                images.append({'filename': rel, 'has_annotation': has_ann, 'annotation_path': str(ann) if has_ann else None})
        
        # Also index any empty folders
        for item in image_folder.iterdir():
            if item.is_dir():
                folders_found.add(item.name)
        
        # Add folders to DB
        for folder in folders_found:
            try:
                dbm.upsert_folder(folder)
            except Exception:
                pass
        
        total = len(images)
        return jsonify({'images': images, 'total': total, 'page': 1, 'page_size': total})

    offset = (page - 1) * page_size
    rows = dbm.list_images(limit=page_size, offset=offset)
    # Keep response shape backward compatible
    images = []
    for r in rows:
        images.append({
            'filename': r['filename'],
            'has_annotation': bool(r['has_annotation']),
            'annotation_path': None,
        })
    return jsonify({'images': images, 'total': total, 'page': page, 'page_size': page_size})


@app.route('/api/folders')
def get_folders():
    """Return a list of folder paths from the DB (including empty folders)."""
    try:
        folders = dbm.list_all_folders()
        
        # If no folders in DB, scan filesystem and add them
        if not folders:
            image_folder = Path(app.config['UPLOAD_FOLDER'])
            for item in image_folder.iterdir():
                if item.is_dir():
                    folder_name = item.name
                    try:
                        dbm.upsert_folder(folder_name)
                        folders.append(folder_name)
                    except Exception as e:
                        print(f"Error adding folder {folder_name}: {e}")
        
    except Exception as e:
        print(f"Error getting folders: {e}")
        folders = []
    return jsonify({'folders': folders})


@app.route('/api/image/<path:filename>')
def get_image(filename):
    """Serve image file with caching headers"""
    response = send_from_directory(app.config['UPLOAD_FOLDER'], filename)
    # Add cache headers to prevent image re-fetching
    response.cache_control.max_age = 3600  # Cache for 1 hour
    response.cache_control.public = True
    return response


@app.route('/api/annotation/<path:filename>')
def get_annotation(filename):
    """Get annotation for a specific image"""
    # Preserve folder structure: ScreenSpot-v2/image.png -> ScreenSpot-v2/image.json
    filename_path = Path(filename)
    annotation_path = Path(app.config['ANNOTATION_FOLDER']) / filename_path.parent / f"{filename_path.stem}.json"
    
    # Fallback: check old location (root of annotations folder) for backward compatibility
    if not annotation_path.exists():
        old_annotation_path = Path(app.config['ANNOTATION_FOLDER']) / f"{filename_path.stem}.json"
        if old_annotation_path.exists():
            # Migrate annotation to new location
            annotation_path.parent.mkdir(parents=True, exist_ok=True)
            shutil.move(str(old_annotation_path), str(annotation_path))
            print(f"Migrated annotation: {old_annotation_path} -> {annotation_path}")
        else:
            return jsonify({'error': 'Annotation not found'}), 404
    
    with open(annotation_path, 'r') as f:
        annotation = json.load(f)
    
    return jsonify(annotation)


@app.route('/api/annotate/<path:filename>', methods=['POST'])
def annotate_image(filename):
    """Generate annotation for an image using OpenAI API"""
    image_path = Path(app.config['UPLOAD_FOLDER']) / filename
    
    if not image_path.exists():
        return jsonify({'error': 'Image not found'}), 404
    
    # Generate annotation using OpenAI API
    try:
        body = request.get_json(silent=True) or {}
        detail_level = body.get('detail_level')
        annotation = annotator.annotate(str(image_path), detail_level=detail_level)
    except Exception as e:
        # The annotator prints detailed diagnostics to stdout/stderr.
        # Return the error string so the frontend can surface it to the user.
        return jsonify({'error': f'Annotation failed: {str(e)}'}), 500
    
    # Save annotation (preserve folder structure)
    filename_path = Path(filename)
    annotation_path = Path(app.config['ANNOTATION_FOLDER']) / filename_path.parent / f"{filename_path.stem}.json"
    annotation_path.parent.mkdir(parents=True, exist_ok=True)
    with open(annotation_path, 'w') as f:
        json.dump(annotation, f, indent=2)
    
    try:
        dbm.set_has_annotation(str(filename), True)
    except Exception:
        pass
    return jsonify(annotation)


@app.route('/api/preprocess/<path:filename>', methods=['POST'])
def preprocess_image(filename):
    """Run preprocessing only and return proposed boxes/points (no LLM)."""
    image_path = Path(app.config['UPLOAD_FOLDER']) / filename
    if not image_path.exists():
        return jsonify({'error': 'Image not found'}), 404
    try:
        body = request.get_json(silent=True) or {}
        max_elems = body.get('max_elements')
        result = annotator.preprocess_only(str(image_path), max_elements=max_elems)
        return jsonify(result)
    except Exception as e:
        return jsonify({'error': f'Preprocess failed: {str(e)}'}), 500


@app.route('/api/image/<path:filename>', methods=['DELETE'])
def delete_image(filename):
    """Delete an image and its annotation"""
    image_path = Path(app.config['UPLOAD_FOLDER']) / filename
    # Preserve folder structure
    filename_path = Path(filename)
    annotation_path = Path(app.config['ANNOTATION_FOLDER']) / filename_path.parent / f"{filename_path.stem}.json"
    
    if not image_path.exists():
        return jsonify({'error': 'Image not found'}), 404
    
    try:
        # Delete image file
        image_path.unlink()
        
        # Delete annotation if exists
        if annotation_path.exists():
            annotation_path.unlink()
        try:
            dbm.delete_image(str(filename))
        except Exception:
            pass
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': f'Failed to delete image: {str(e)}'}), 500


@app.route('/api/annotation/<path:filename>', methods=['PUT'])
def update_annotation(filename):
    """Update annotation for an image"""
    # Preserve folder structure
    filename_path = Path(filename)
    annotation_path = Path(app.config['ANNOTATION_FOLDER']) / filename_path.parent / f"{filename_path.stem}.json"
    annotation_path.parent.mkdir(parents=True, exist_ok=True)
    
    annotation_data = request.json
    
    with open(annotation_path, 'w') as f:
        json.dump(annotation_data, f, indent=2)
    try:
        dbm.set_has_annotation(str(filename), True)
    except Exception:
        pass
    return jsonify({'success': True})


@app.route('/api/annotation/<path:filename>/paste', methods=['POST'])
def paste_annotation(filename):
    """
    Create annotation from pasted JSON
    Allows users to paste their own annotation JSON instead of using AI generation
    """
    try:
        # Get the pasted JSON data
        pasted_data = request.json.get('annotation')
        
        if not pasted_data:
            return jsonify({'error': 'No annotation data provided'}), 400
        
        # Validate the annotation structure
        if 'img_size' not in pasted_data or 'element' not in pasted_data:
            return jsonify({'error': 'Invalid annotation format. Must contain "img_size" and "element" fields'}), 400
        
        # Validate img_size
        if not isinstance(pasted_data['img_size'], list) or len(pasted_data['img_size']) != 2:
            return jsonify({'error': 'img_size must be a list of [width, height]'}), 400
        
        # Validate elements
        if not isinstance(pasted_data['element'], list):
            return jsonify({'error': 'element must be a list'}), 400
        
        for idx, elem in enumerate(pasted_data['element']):
            if not isinstance(elem, dict):
                return jsonify({'error': f'Element {idx} must be an object'}), 400
            
            if 'instruction' not in elem or 'bbox' not in elem or 'point' not in elem:
                return jsonify({'error': f'Element {idx} must have instruction, bbox, and point fields'}), 400
            
            if not isinstance(elem['bbox'], list) or len(elem['bbox']) != 4:
                return jsonify({'error': f'Element {idx} bbox must be [x1, y1, x2, y2]'}), 400
            
            if not isinstance(elem['point'], list) or len(elem['point']) != 2:
                return jsonify({'error': f'Element {idx} point must be [x, y]'}), 400
        
        # Save the annotation (preserve folder structure)
        filename_path = Path(filename)
        annotation_path = Path(app.config['ANNOTATION_FOLDER']) / filename_path.parent / f"{filename_path.stem}.json"
        annotation_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(annotation_path, 'w') as f:
            json.dump(pasted_data, f, indent=2)
        try:
            dbm.set_has_annotation(str(filename), True)
        except Exception:
            pass
        return jsonify({'success': True, 'annotation': pasted_data})
        
    except json.JSONDecodeError as e:
        return jsonify({'error': f'Invalid JSON format: {str(e)}'}), 400
    except Exception as e:
        return jsonify({'error': f'Error processing annotation: {str(e)}'}), 500


@app.route('/api/annotation/<path:filename>/element/<int:element_index>', methods=['DELETE'])
def delete_element(filename, element_index):
    """Delete a specific element from annotation"""
    # Preserve folder structure
    filename_path = Path(filename)
    annotation_path = Path(app.config['ANNOTATION_FOLDER']) / filename_path.parent / f"{filename_path.stem}.json"
    
    # Fallback: check old location for backward compatibility
    if not annotation_path.exists():
        old_annotation_path = Path(app.config['ANNOTATION_FOLDER']) / f"{filename_path.stem}.json"
        if old_annotation_path.exists():
            annotation_path.parent.mkdir(parents=True, exist_ok=True)
            shutil.move(str(old_annotation_path), str(annotation_path))
        else:
            return jsonify({'error': 'Annotation not found'}), 404
    
    with open(annotation_path, 'r') as f:
        annotation = json.load(f)
    
    if 0 <= element_index < len(annotation.get('element', [])):
        annotation['element'].pop(element_index)
        
        with open(annotation_path, 'w') as f:
            json.dump(annotation, f, indent=2)
        
        return jsonify({'success': True, 'annotation': annotation})
    
    return jsonify({'error': 'Invalid element index'}), 400


@app.route('/api/visualize/<path:filename>')
def visualize_image(filename):
    """Get visualized image with annotations"""
    image_path = Path(app.config['UPLOAD_FOLDER']) / filename
    # Preserve folder structure
    filename_path = Path(filename)
    annotation_path = Path(app.config['ANNOTATION_FOLDER']) / filename_path.parent / f"{filename_path.stem}.json"
    
    if not image_path.exists():
        return jsonify({'error': 'Image not found'}), 404
    
    # Fallback: check old location for backward compatibility
    if not annotation_path.exists():
        old_annotation_path = Path(app.config['ANNOTATION_FOLDER']) / f"{filename_path.stem}.json"
        if old_annotation_path.exists():
            annotation_path.parent.mkdir(parents=True, exist_ok=True)
            shutil.move(str(old_annotation_path), str(annotation_path))
        else:
            return jsonify({'error': 'Annotation not found'}), 404
    
    with open(annotation_path, 'r') as f:
        annotation = json.load(f)
    
    # Generate visualization
    vis_image_base64 = visualize_annotations(str(image_path), annotation)
    
    return jsonify({'image': vis_image_base64})


@app.route('/api/upload', methods=['POST'])
def upload_file():
    """Upload new image"""
    if 'file' not in request.files:
        return jsonify({'error': 'No file part'}), 400
    
    file = request.files['file']
    
    if file.filename == '':
        return jsonify({'error': 'No selected file'}), 400
    
    if file:
        relative_path = request.form.get('relative_path', '')
        
        if relative_path:
            parts = Path(relative_path).parts
            if len(parts) > 1:
                safe_parts = [secure_filename(p) for p in parts]
                filename = '/'.join(safe_parts[1:])
            else:
                filename = secure_filename(file.filename)
        else:
            filename = secure_filename(file.filename)
        
        file_path = Path(app.config['UPLOAD_FOLDER']) / filename
        file_path.parent.mkdir(parents=True, exist_ok=True)
        file.save(str(file_path))
        try:
            size_b = None
            try:
                size_b = file_path.stat().st_size
            except Exception:
                pass
            ann_path = Path(app.config['ANNOTATION_FOLDER']) / f"{file_path.stem}.json"
            dbm.upsert_image(filename, has_annotation=ann_path.exists(), size_bytes=size_b)
        except Exception:
            pass
        return jsonify({'success': True, 'filename': filename})


@app.route('/api/folder', methods=['POST'])
def create_folder():
    data = request.get_json(silent=True) or {}
    name = data.get('name', '').strip()
    if not name:
        return jsonify({'error': 'Missing folder name'}), 400
    safe = secure_filename(name)
    folder_path = Path(app.config['UPLOAD_FOLDER']) / safe
    try:
        folder_path.mkdir(parents=True, exist_ok=True)
        # Add folder to database so it shows up in folder view
        dbm.upsert_folder(safe)
        return jsonify({'success': True, 'folder': str(safe)})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/batch-annotate', methods=['POST'])
def batch_annotate():
    """Start an asynchronous batch annotation job over all images. Returns a job_id."""
    image_folder = Path(app.config['UPLOAD_FOLDER'])
    body = request.get_json(silent=True) or {}
    force = body.get('force', False)

    images = []
    filenames = body.get('filenames')
    if isinstance(filenames, list) and filenames:
        # Limit to provided filenames
        allowed_ext = {'.jpg', '.jpeg', '.png', '.gif', '.bmp'}
        for name in filenames:
            try:
                # normalize path
                p = image_folder / str(name)
                if p.is_file() and p.suffix.lower() in allowed_ext:
                    images.append({'path': p})
            except Exception:
                continue
    else:
        # All images
        for img_path in image_folder.rglob('*'):
            if img_path.is_file() and img_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']:
                images.append({'path': img_path})

    job_id = job_manager.create_job(images, force)
    job = job_manager.get_job(job_id)
    return jsonify({'job_id': job_id, 'total': job.get('total', 0)})


@app.route('/api/batch-annotate/status/<job_id>')
def batch_status(job_id):
    job = job_manager.get_job(job_id)
    if not job:
        return jsonify({'error': 'job_not_found'}), 404
    return jsonify(job)


@app.route('/api/batch-annotate/stream/<job_id>')
def batch_stream(job_id):
    stream = job_manager.sse_stream(job_id)
    return Response(stream, mimetype='text/event-stream')


@app.route('/api/move-images', methods=['POST'])
def move_images():
    """Move images to a target folder."""
    body = request.get_json(silent=True) or {}
    filenames = body.get('filenames', [])
    target_folder = body.get('target_folder', '').strip()
    
    if not filenames:
        return jsonify({'error': 'No images selected'}), 400
    
    if not target_folder:
        return jsonify({'error': 'No target folder specified'}), 400
    
    image_folder = Path(app.config['UPLOAD_FOLDER'])
    annotation_folder = Path(app.config['ANNOTATION_FOLDER'])
    target_path = image_folder / target_folder
    
    # Ensure target folder exists
    target_path.mkdir(parents=True, exist_ok=True)
    
    moved_count = 0
    errors = []
    
    for filename in filenames:
        try:
            source_path = image_folder / filename
            if not source_path.exists():
                errors.append(f'{filename}: not found')
                continue
            
            # Get just the filename without any path
            base_name = Path(filename).name
            dest_path = target_path / base_name
            
            # Skip if source and destination are the same
            if source_path.resolve() == dest_path.resolve():
                continue
            
            # Check if destination already exists
            if dest_path.exists():
                errors.append(f'{base_name}: already exists in target folder')
                continue
            
            # Move the image file
            shutil.move(str(source_path), str(dest_path))
            
            # Move annotation if it exists
            # Use the full relative path for annotation lookup
            filename_path = Path(filename)
            ann_source = annotation_folder / filename_path.parent / f"{filename_path.stem}.json"
            if ann_source.exists():
                ann_dest_dir = annotation_folder / target_folder
                ann_dest_dir.mkdir(parents=True, exist_ok=True)
                ann_dest_file = ann_dest_dir / f"{base_name.rsplit('.', 1)[0]}.json"
                shutil.move(str(ann_source), str(ann_dest_file))
            
            # Update database
            new_path = f"{target_folder}/{base_name}"
            try:
                dbm.delete_image(str(filename))
                has_ann = (annotation_folder / target_folder / f"{base_name.rsplit('.', 1)[0]}.json").exists()
                dbm.upsert_image(new_path, has_annotation=has_ann)
            except Exception as e:
                print(f"DB update error for {filename}: {e}")
            
            moved_count += 1
            
        except Exception as e:
            errors.append(f'{filename}: {str(e)}')
            continue
    
    return jsonify({
        'success': True,
        'moved': moved_count,
        'errors': errors
    })


@app.route('/api/export', methods=['POST'])
def export_dataset():
    """Export selected images to specified format with optional zip."""
    import subprocess
    import tempfile
    import zipfile
    
    body = request.get_json(silent=True) or {}
    filenames = body.get('filenames', [])
    split_name = body.get('split', 'train')
    export_format = body.get('format', 'showui-desktop')
    create_zip = body.get('create_zip', False)
    
    if not filenames:
        return jsonify({'error': 'No images selected'}), 400
    
    # Create temporary output directory
    timestamp = int(time.time())
    output_dir = Path(tempfile.gettempdir()) / f'{export_format}_export_{timestamp}'
    output_dir.mkdir(parents=True, exist_ok=True)
    
    try:
        # Route to appropriate export script based on format
        if export_format == 'showui-desktop':
            script_path = Path(__file__).parent / 'scripts' / 'export_showui_desktop.py'
            images_path = Path(app.config['UPLOAD_FOLDER'])
            annotations_path = Path(app.config['ANNOTATION_FOLDER'])
            
            result = subprocess.run(
                [
                    'python3', str(script_path),
                    '--images', str(images_path),
                    '--annotations', str(annotations_path),
                    '--output', str(output_dir),
                    '--split', split_name,
                    '--filenames', json.dumps(filenames)
                ],
                capture_output=True,
                text=True,
                timeout=300
            )
            
            if result.returncode != 0:
                print(f"Export script failed with return code {result.returncode}")
                print(f"STDOUT: {result.stdout}")
                print(f"STDERR: {result.stderr}")
                return jsonify({
                    'error': 'Export failed',
                    'details': result.stderr or result.stdout or 'Unknown error'
                }), 500
        else:
            # Placeholder for other export formats
            return jsonify({'error': f'Export format "{export_format}" not implemented yet'}), 400
        
        # Count exported files
        exported_images = len(list((output_dir / 'images').rglob('*'))) if (output_dir / 'images').exists() else 0
        
        response_data = {
            'success': True,
            'output_path': str(output_dir),
            'exported_images': exported_images,
            'format': export_format,
            'message': f'Exported {exported_images} images to {output_dir}'
        }
        
        # Create zip if requested
        if create_zip:
            zip_path = Path(tempfile.gettempdir()) / f'{export_format}_{split_name}_{timestamp}.zip'
            
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, dirs, files in os.walk(output_dir):
                    for file in files:
                        file_path = Path(root) / file
                        arcname = file_path.relative_to(output_dir)
                        zipf.write(file_path, arcname)
            
            zip_size = zip_path.stat().st_size
            response_data['zip_path'] = str(zip_path)
            response_data['zip_size'] = zip_size
            response_data['zip_name'] = zip_path.name
        
        return jsonify(response_data)
        
    except subprocess.TimeoutExpired:
        return jsonify({'error': 'Export timeout'}), 500
    except Exception as e:
        return jsonify({'error': f'Export failed: {str(e)}'}), 500


@app.route('/api/download-export')
def download_export():
    """Download exported dataset zip file."""
    zip_path = request.args.get('path')
    
    if not zip_path:
        return jsonify({'error': 'No zip path provided'}), 400
    
    zip_path = Path(zip_path)
    
    if not zip_path.exists():
        return jsonify({'error': 'Export file not found'}), 404
    
    # Security check: ensure the file is in temp directory
    if not str(zip_path).startswith(tempfile.gettempdir()):
        return jsonify({'error': 'Invalid file path'}), 403
    
    try:
        return send_from_directory(
            zip_path.parent,
            zip_path.name,
            as_attachment=True,
            download_name=zip_path.name
        )
    except Exception as e:
        return jsonify({'error': f'Download failed: {str(e)}'}), 500


@app.route('/api/deduplicate', methods=['POST'])
def deduplicate_images():
    """Remove duplicate images, keeping annotated versions."""
    try:
        images = dbm.list_images(limit=100000)
        
        # Group by base filename
        from collections import defaultdict
        filename_groups = defaultdict(list)
        
        for img in images:
            base_name = Path(img['filename']).name
            filename_groups[base_name].append(img)
        
        # Find duplicates and remove non-annotated ones
        removed_count = 0
        kept_count = 0
        errors = []
        
        for base_name, group in filename_groups.items():
            if len(group) <= 1:
                continue
            
            # Sort by has_annotation (annotated first)
            group.sort(key=lambda x: x['has_annotation'], reverse=True)
            
            # Keep the first one (most likely to be annotated)
            to_keep = group[0]
            to_remove = group[1:]
            
            kept_count += 1
            
            for img in to_remove:
                try:
                    filename = img['filename']
                    image_path = Path(app.config['UPLOAD_FOLDER']) / filename
                    filename_path = Path(filename)
                    annotation_path = Path(app.config['ANNOTATION_FOLDER']) / filename_path.parent / f"{filename_path.stem}.json"
                    
                    # Delete files
                    if image_path.exists():
                        image_path.unlink()
                    if annotation_path.exists():
                        annotation_path.unlink()
                    
                    # Delete from database
                    dbm.delete_image(str(filename))
                    removed_count += 1
                    
                except Exception as e:
                    errors.append(f'{img["filename"]}: {str(e)}')
        
        return jsonify({
            'success': True,
            'removed': removed_count,
            'kept': kept_count,
            'errors': errors
        })
        
    except Exception as e:
        return jsonify({'error': f'Deduplication failed: {str(e)}'}), 500


@app.route('/api/folder/<path:folder_path>', methods=['DELETE'])
def delete_folder(folder_path):
    """Delete a folder and all its contents."""
    try:
        folder_full_path = Path(app.config['UPLOAD_FOLDER']) / folder_path
        annotation_folder_path = Path(app.config['ANNOTATION_FOLDER']) / folder_path
        
        if not folder_full_path.exists():
            return jsonify({'error': 'Folder not found'}), 404
        
        if not folder_full_path.is_dir():
            return jsonify({'error': 'Not a folder'}), 400
        
        # Delete all images in database under this folder
        images = dbm.list_images(limit=100000)
        deleted_count = 0
        
        for img in images:
            if img['filename'].startswith(folder_path + '/'):
                try:
                    dbm.delete_image(img['filename'])
                    deleted_count += 1
                except Exception:
                    pass
        
        # Delete physical folders
        if folder_full_path.exists():
            shutil.rmtree(folder_full_path)
        
        if annotation_folder_path.exists():
            shutil.rmtree(annotation_folder_path)
        
        # Delete folder from database
        try:
            dbm.delete_folder(folder_path)
        except Exception:
            pass
        
        return jsonify({
            'success': True,
            'deleted_images': deleted_count,
            'message': f'Deleted folder and {deleted_count} images'
        })
        
    except Exception as e:
        return jsonify({'error': f'Delete failed: {str(e)}'}), 500


if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000, threaded=True)

